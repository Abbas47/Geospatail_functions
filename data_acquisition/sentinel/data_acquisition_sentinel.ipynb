{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "import time\n",
    "start_data_acquistion = time.time()\n",
    "import os\n",
    "import boto3\n",
    "import shutil\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import box, shape, Polygon\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from ipyleaflet import Map, basemaps, ScaleControl, DrawControl, SearchControl, Marker, AwesomeIcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input for path\n",
    "# local path\n",
    "aoi_path = ''\n",
    "download_directory_path = ''\n",
    "\n",
    "# s3 path\n",
    "bucket_name = ''\n",
    "drive_path = ''\n",
    "\n",
    "### input for functiond\n",
    "user = 'ab02' # mention copernicus user name\n",
    "password = 'Copernicus@02' # mention password\n",
    "satellite = 'sentinel-1' # input 'sentinel-1' or 'sentinel-2' for data needs to be downloaded\n",
    "week_start_date = '2023-08-19' #YY-MM-DD\n",
    "week_end_date = '2023-08-25' #YY-MM-DD\n",
    "start_date = datetime.strptime(week_start_date, '%Y-%m-%d').date() # start date of the search period (format: YY,MM,DD)\n",
    "end_date = datetime.strptime(week_end_date, '%Y-%m-%d').date() # end date of the search period (format: YY,MM,DD)\n",
    "end_date = end_date + timedelta(days=1) # adding +1 day to end date to include the end date into the data search\n",
    "orbit_direction =  '*' # 'ASCENDING' or 'DESCENDING' or '*' ('*' - return all product, i.e., ascending and descending)\n",
    "polarisation = 'VV+VH' # input 'HH' or 'VV' or 'HV' or 'VH' or 'HH+HV' or 'VV+VH' polarization band\n",
    "sensor_mode = 'IW' # input 'IW' or 'EW'\n",
    "product_type = 'GRD' # input 'GRD' or 'SLC or 'S2MSI1C' (type of product for sentinel1 - 'GRD' or 'SLC' and for sentine2 - 'S2MSI1C')\n",
    "cloud_coverage_percentage = 30 # mention percetage of cloud cover for the data search\n",
    "relation = 'Intersects' # input 'Intersects' or 'Contains' or 'Iswithin' (Intersects -- true if the AOI and the footprint intersect (default), Contains -- true if the AOI is inside the footprint, and IsWithin -- true if the footprint is inside the AOI)\n",
    "remove = False # input, i.e., True or False. if remove=True, the data used and generated from this script will be removed from local instance and if remove=False, then the data will not be removed from local instance. Deafult to False\n",
    "upload = False # input, i.e., True or False. if upload=True, the data will be uploaded to s3 based on the path provided bu user and if upload=False, then the data will not be uploaded to s3. Deafult to False \n",
    "draw_poly = True # input, i.e., True or False. if draw_poly=True, the aoi will be created manually on basemap or created using the defined point and if draw_poly=False, aoi shp/geojson path is provided. Deafult to False\n",
    "if draw_poly == True:\n",
    "    aoi_name = input(\"Enter define aoi name:\")\n",
    "    point = input(\"Is the point is available for creating aoi around it, type Yes if available or type No if not available:\")\n",
    "    if point == 'Yes':\n",
    "        latitude = input(\"Enter latitude of point:\")\n",
    "        longitude = input(\"Enter longitude of the point:\")\n",
    "        offset_degrees = input(\"Enter offset in degree to create bounding box around the point:\") or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "def create_bbox(latitude, longitude, offset_degrees=None):\n",
    "    '''\n",
    "    Function for creating bounding box around the lat and long based on the user input\n",
    "    1. latitude: define latitude\n",
    "    2. longitude: define longitude\n",
    "    3. offset_degrees: define offset to create a rectangle around the lat,long\n",
    "\n",
    "    Output:\n",
    "    Return geodata frame \n",
    "    '''\n",
    "    if offset_degrees == None:\n",
    "        # Calculate the degree offsets for the rectangle\n",
    "        offset_degrees = 0.025  # 0.025 degrees is approximately 2.75 km at the equator\n",
    "\n",
    "    # Calculate the coordinates for the rectangle's corners\n",
    "    min_lon = longitude - offset_degrees\n",
    "    max_lon = longitude + offset_degrees\n",
    "    min_lat = latitude - offset_degrees\n",
    "    max_lat = latitude + offset_degrees\n",
    "\n",
    "    # Create a GeoDataFrame with a single rectangular polygon\n",
    "    geometry = [box(min_lon, min_lat, max_lon, max_lat)]\n",
    "    gdf = gpd.GeoDataFrame(geometry=geometry, crs=\"EPSG:4326\")\n",
    "    return gdf\n",
    "\n",
    "def sentinel1(api, footprint, start_date, end_date, Satellite, product_type, sensor_mode, polarisation, relation, orbit_direction, metadata_file_path, imagery_path):\n",
    "    '''\n",
    "    Function for querying sentinel1 data\n",
    "    1. api: sentinel API\n",
    "    2. start_date: start date of the search period \n",
    "    3. end_date: end date of the search period\n",
    "    4. satellite: 'sentinel-1'\n",
    "    5. product_type: 'S2MSI1C' (type of data provided by sentinel2)\n",
    "    6. sensor_mode: 'IW' or 'EW' (type of sensor provided by sentinel1)\n",
    "    7. polarisation: 'HH' or 'VV' or 'HV' or 'VH' or 'HH+HV' or 'VV+VH' (type of polarization bands offer by sentinel1)\n",
    "    8. relation: 'Intersects' or 'Contains' or 'Iswithin' [Intersects: true if the AOI and the footprint intersect (default), Contains: true if the AOI is inside the footprint, and IsWithin: true if the footprint is inside the AOI]\n",
    "    9. orbit_direction: 'ASCENDING' or 'DESCENDING' or '*' ('*' -- Ascendin and Descending)\n",
    "    10. metadata_path: Location where the metadata csv will be saved\n",
    "    11. imagery_path: Location where the imageries csv will be saved\n",
    "\n",
    "    Output:\n",
    "    Return products\n",
    "    '''\n",
    "    print(f'Data is downloading from Sentinel1....')\n",
    "    products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = Satellite,\n",
    "                     producttype = product_type,\n",
    "                     sensoroperationalmode = sensor_mode,\n",
    "                     polarisationmode = polarisation,\n",
    "                     area_relation = relation,\n",
    "                     orbitdirection = orbit_direction)\n",
    "    \n",
    "    # print('Total images: ', len(products)) # Number of images are available\n",
    "    # GeoPandas GeoDataFrame with the metadata of the scenes and the footprints as geometries\n",
    "    products_df = api.to_dataframe(products)\n",
    "    products_df.to_csv(metadata_file_path)\n",
    "    \n",
    "    # download all results from the search\n",
    "    api.download_all(products, directory_path = imagery_path,)\n",
    "    return products\n",
    "    \n",
    "def sentinel2(api, footprint, start_date, end_date, Satellite, product_type, cloud_coverage_percentage, relation, metadata_file_path, imagery_path):\n",
    "    '''\n",
    "    Function for querying sentinel2 data\n",
    "    1. api: sentinel API\n",
    "    2. start_date: start date of the search period \n",
    "    3. end_date: end date of the search period\n",
    "    4. satellite: 'sentinel-2'\n",
    "    5. colud_coverage_precentage: define percetage of cloud cover for the data search\n",
    "    6. relation: 'Intersects' or 'Contains' or 'Iswithin' [Intersects: true if the AOI and the footprint intersect (default), Contains: true if the AOI is inside the footprint, and IsWithin: true if the footprint is inside the AOI]\n",
    "    7. metadata_path: Location where the metadata csv will be saved\n",
    "    8. imagery_path: Location where the imageries csv will be saved\n",
    "\n",
    "    Output:\n",
    "    Return products\n",
    "    '''\n",
    "    print(f'Data is downloading from Sentinel2....')\n",
    "    products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = Satellite,\n",
    "                     producttype = product_type,\n",
    "                     cloudcoverpercentage = (0, cloud_coverage_percentage),\n",
    "                     area_relation = relation)\n",
    "    \n",
    "    # print('Total images: ', len(products)) # Number of images are available\n",
    "    # GeoPandas GeoDataFrame with the metadata of the scenes and the footprints as geometries\n",
    "    products_df = api.to_geodataframe(products)\n",
    "    products_df.to_csv(metadata_file_path)\n",
    "    \n",
    "    # download all results from the search\n",
    "    api.download_all(products, directory_path = imagery_path,)\n",
    "    return products\n",
    "\n",
    "def s3_upload(bucket_name, local_path, drive_path):\n",
    "    '''\n",
    "    Function is to upload the whole directory data to the desired location on s3\n",
    "    Input parameters\n",
    "    1. bucket_name: Define the name of the s3 bucket where data needs to be uploaded\n",
    "    2. local_path: Location of the directory in the local instance\n",
    "    3. drive_path: Location of the directory in the s3 bucket\n",
    "    '''\n",
    "    print(f'Data is uploading from local to s3....')\n",
    "    s3 = boto3.client('s3')\n",
    "    for file in os.listdir(local_path):\n",
    "        if not file.startswith('.'):\n",
    "            local_file_path = os.path.join(local_path, file)\n",
    "            drive_file_path = os.path.join(drive_path, file)\n",
    "            s3.upload_file(Filename=local_file_path, Bucket=bucket_name, Key=drive_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09215c045a74033bc01f0ddd6fcf9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.128, 2.588], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if draw_poly == True and point == 'No':\n",
    "  # Create ipyleaflet map, add tile layer, and display\n",
    "  center = [38.128, 2.588]\n",
    "  zoom = 5\n",
    "\n",
    "  m = Map(basemap=basemaps.Esri.WorldTopoMap, center=center, zoom=zoom)\n",
    "  m.add_control(ScaleControl(position='bottomleft'))\n",
    "\n",
    "  marker = Marker(icon=AwesomeIcon(name=\"check\", marker_color='green', icon_color='darkgreen'))\n",
    "\n",
    "  m.add_control(SearchControl(\n",
    "    position=\"topright\",\n",
    "    url='https://nominatim.openstreetmap.org/search?format=json&q={s}',\n",
    "    zoom=5,\n",
    "    marker=marker\n",
    "  ))\n",
    "\n",
    "  draw_control = DrawControl(\n",
    "      marker={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "      rectangle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "      circle={\"shapeOptions\": {\"color\": \"#0000FF\"}},\n",
    "      circlemarker={},\n",
    "  )\n",
    "  m.add(draw_control)\n",
    "  display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_poly == True:\n",
    "    if point == 'Yes':\n",
    "        gdf_bounds = create_bbox(latitude, longitude)\n",
    "    elif point == 'No':\n",
    "        polygon = shape(draw_control.last_draw.get('geometry'))\n",
    "        gdf = gpd.GeoDataFrame(index=[0], crs='epsg:4326', geometry=[polygon])\n",
    "        bounds = gdf.total_bounds \n",
    "        gdf_bounds = gpd.GeoSeries([box(*bounds)])\n",
    "\n",
    "    footprint = gdf_bounds.to_wkt().values.tolist()[0]\n",
    "\n",
    "elif draw_poly == False:\n",
    "    if aoi_path.endswith('.geojson'):\n",
    "        # read geojson\n",
    "        footprint = geojson_to_wkt(read_geojson(aoi_path))\n",
    "    elif aoi_path.endswith('.shp'):\n",
    "        # read shapefile\n",
    "        gdf = gpd.read_file(aoi_path)\n",
    "        bounds = gdf.total_bounds\n",
    "        gdf_bounds = gpd.GeoSeries([box(*bounds)])\n",
    "        footprint = gdf_bounds.to_wkt().values.tolist()[0]\n",
    "    aoi_name = pathlib.Path(aoi_path).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the sentinelsat API using user name and password\n",
    "api = SentinelAPI(user, password)\n",
    "\n",
    "metadata_file_path = os.path.join(download_directory_path, f'{aoi_name}_acqusition_{week_start_date}_{week_end_date}.csv')\n",
    "\n",
    "if satellite == 'sentinel-1':\n",
    "    products = sentinel1(api, \n",
    "                            footprint, \n",
    "                            start_date, \n",
    "                            end_date, satellite, \n",
    "                            product_type, \n",
    "                            sensor_mode, \n",
    "                            polarisation, \n",
    "                            relation, \n",
    "                            orbit_direction, metadata_file_path, download_directory_path)\n",
    "elif satellite == 'sentinel-2':\n",
    "    products = sentinel2(api, \n",
    "                         footprint, \n",
    "                         start_date, \n",
    "                         end_date, \n",
    "                         satellite, \n",
    "                         product_type, \n",
    "                         cloud_coverage_percentage,\n",
    "                         relation, metadata_file_path, download_directory_path)\n",
    "\n",
    "    downloaded_img = [file for file in Path(download_directory_path).rglob('*.zip')]\n",
    "    print('Total avaliable images: ', len(products)) # Number of images are available\n",
    "    # print(downloaded_img)\n",
    "    print('Total downloaded images: ', len(downloaded_img)) # Number of images downloaded\n",
    "\n",
    "    ### Export to s3\n",
    "    if upload == True:\n",
    "        # Connect to S3 bucket and download file \n",
    "        s3_upload(bucket_name, download_directory_path, drive_path)\n",
    "    elif upload == False:\n",
    "        pass\n",
    "    \n",
    "    # remove the data from the local\n",
    "    if remove == True:\n",
    "        shutil.rmtree(download_directory_path)  # remove raw imagery folder\n",
    "    elif remove == False:\n",
    "        pass\n",
    "\n",
    "    end = time.time()\n",
    "    end_data_acquistion = time.time()\n",
    "    print(\"The time of execution of data acquistion script:\",(end_data_acquistion-start_data_acquistion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
